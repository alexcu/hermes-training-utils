{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from scipy import misc\n",
    "from glob import glob\n",
    "import json\n",
    "import cv2\n",
    "from wand.image import Image\n",
    "from tempfile import mkstemp\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input directory\n",
    "indir = \"/Users/Alex/Desktop/tagging_iterations\"\n",
    "\n",
    "# How many times to augment one image\n",
    "augment_times = 25\n",
    "\n",
    "# Load in images *ALL*\n",
    "PROCESS_ALL_IMAGES = True\n",
    "dataset = \"21-07-2017\"\n",
    "\n",
    "# Setup output\n",
    "outdir = \"/Users/Alex/Desktop/augmented_images/%s\" % dataset\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Resize all our images to SCALE%; map coordinates to new scale\n",
    "SCALE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in photos, their labels, then the image, then zip together\n",
    "glob_d = \"%s/%s/**/%s.jpg\" % (indir, dataset, (\"*\" if PROCESS_ALL_IMAGES else \"*248 (4)\"))\n",
    "labels = [json.load((open(\"%s.json\" % p))) for p in glob(glob_d) if os.path.exists(\"%s.json\" % p)]\n",
    "\n",
    "# Declare temporary files which we will eventually clean up\n",
    "temp_files = []\n",
    "        \n",
    "def photo_has_runners(label):\n",
    "    # Returns true if the label has runners\n",
    "    return len(label[\"TaggedRunners\"]) > 0\n",
    "\n",
    "# Reject labels that are not tagged\n",
    "labels = [label for label in labels if photo_has_runners(label)]\n",
    "image_identifiers = [label[\"Identifier\"] for label in labels]\n",
    "files_to_accept = tuple([\"%s.jpg\" % img_id for img_id in image_identifiers])\n",
    "image_files = [image_file for image_file in glob(glob_d) if image_file.endswith(files_to_accept)]\n",
    "\n",
    "def load_image(filename):\n",
    "    # Must auto-orient (and scale) all images\n",
    "    # Saves it to a temporary file that is deleted once done\n",
    "    with Image(filename=filename) as img:\n",
    "        img.auto_orient()\n",
    "        img.resize(int(img.width * SCALE), int(img.height * SCALE))\n",
    "        fp, temp_file = mkstemp()\n",
    "        temp_files.append((fp, temp_file))\n",
    "        print \"Generating %s%% sampled version of '%s' to '%s'...\" % (SCALE * 100, filename, temp_file)\n",
    "        img.save(filename=temp_file)\n",
    "    return misc.imread(temp_file)\n",
    "\n",
    "def clean_temp_files():\n",
    "    # Cleans all temporary files\n",
    "    for (fp, temp_path) in temp_files:\n",
    "        print \"Deleting tempfile %s...\" % temp_path\n",
    "        os.close(fp)\n",
    "        os.remove(temp_path)\n",
    "\n",
    "# Load in the images\n",
    "images = [load_image(filename) for filename in image_files]\n",
    "\n",
    "def extract_bib_keypoints_on_image_from_label(label):    \n",
    "    # Extracts bib keypoints from the data labels\n",
    "    def extract_bib_keypoint_from_coords_str(coords_str):\n",
    "        # Extracts scaled keypoints from the coords_str (i.e., \"200, 300\" => x=200, y=300)\n",
    "        coords = [ int(int(pt) * SCALE) for pt in coords_str.split(', ') ]\n",
    "        keypoint = ia.Keypoint(x=coords[0], y=coords[1])\n",
    "        return keypoint\n",
    "    \n",
    "    def extract_bib_keypoints_from_runner(runner):\n",
    "        # Extracts keypoints from specific runner\n",
    "        coords = runner[\"Bib\"][\"PixelPoints\"]\n",
    "        return [ extract_bib_keypoint_from_coords_str(c) for c in coords ]\n",
    "    \n",
    "    # Extract the image\n",
    "    image = images[image_identifiers.index(label[\"Identifier\"])]\n",
    "    \n",
    "    # Flatten each runner down\n",
    "    keypoints = np.array([ extract_bib_keypoints_from_runner(runner) for runner in label[\"TaggedRunners\"] ]).flatten()\n",
    "    \n",
    "    # Return a single KeypointsOnImage\n",
    "    return ia.KeypointsOnImage(keypoints, shape=image.shape)\n",
    "    \n",
    "# Extract all bib sheets and their respective coordinates and map to scaled matrix\n",
    "keypoints = [ extract_bib_keypoints_on_image_from_label(label) for label in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def affine():\n",
    "    # Affine transformation\n",
    "    TRANSLATE_PCT_RANGE = 0.35\n",
    "    ROTATION_RANGE = (-45,45)\n",
    "    SHEAR_RANGE = (-5,5) \n",
    "    \n",
    "    translate_percent = {\n",
    "        \"x\": (-TRANSLATE_PCT_RANGE, +TRANSLATE_PCT_RANGE),\n",
    "        \"y\": (-TRANSLATE_PCT_RANGE, +TRANSLATE_PCT_RANGE),\n",
    "    }\n",
    "    rotate=ROTATION_RANGE\n",
    "    shear=SHEAR_RANGE\n",
    "    mode = \"edge\"\n",
    "    \n",
    "    return iaa.Affine(translate_percent=translate_percent,\n",
    "                      rotate=rotate,\n",
    "                      shear=shear,\n",
    "                      mode=mode)\n",
    "\n",
    "def add_neg():\n",
    "    # Applies a negative to all channels\n",
    "    return iaa.Add((-45, 0))\n",
    "\n",
    "def add_pos():\n",
    "    # Applies a positive to all channels\n",
    "    return iaa.Add((0, 45))\n",
    "\n",
    "def mul_neg():\n",
    "    # Multiples all channels by a negative factor\n",
    "    return iaa.Multiply((0.5, 1))\n",
    "\n",
    "def mul_pos():\n",
    "    # Multiples all channels by a postive factor\n",
    "    return iaa.Multiply((1, 1.5))\n",
    "\n",
    "def blur():\n",
    "    # Chooses one of three blur methods\n",
    "    return one_of([\n",
    "        iaa.GaussianBlur((0, 3.0)),\n",
    "        iaa.AverageBlur(k=(2, 4)),\n",
    "        iaa.MedianBlur(k=(3, 5)),\n",
    "    ])\n",
    "\n",
    "# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "def sometimes(aug, pct = 0.5):\n",
    "    return iaa.Sometimes(pct, aug)\n",
    "    \n",
    "def one_of(funcs):\n",
    "    # Shortcut for iaa.OneOf\n",
    "    return iaa.OneOf(funcs)\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        affine(),\n",
    "        sometimes(one_of([add_pos(), add_neg()])),\n",
    "        sometimes(one_of([mul_pos(), mul_neg()])),\n",
    "        sometimes(blur(), 0.3)\n",
    "    ],\n",
    "    random_order=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keypoints_per_person(kpts):\n",
    "    # Group one keypoint per person (mod 4)\n",
    "    return [kpts.keypoints[i:i + 4] for i in range(0, len(kpts.keypoints), 4)]\n",
    "\n",
    "def plot_img(src_image, src_keypoints, aug_image, aug_keypoints, aug_rects):\n",
    "    # Plots image\n",
    "    def plot_keypoints_on_ax(kpts, ax_id):\n",
    "        polys = keypoints_per_person(kpts)\n",
    "        for poly in polys:\n",
    "            coords = [[coords.x, coords.y] for coords in poly]\n",
    "            ax[ax_id].add_patch(patches.Polygon(coords, linewidth=3, edgecolor='lime', fill=False))\n",
    "    \n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].imshow(src_image)\n",
    "    ax[1].imshow(aug_image)\n",
    "    plot_keypoints_on_ax(src_keypoints, 0)\n",
    "    plot_keypoints_on_ax(aug_keypoints, 1)\n",
    "    \n",
    "    for rect in aug_rects:\n",
    "        width = rect[\"max_x\"] - rect[\"min_x\"]\n",
    "        height = rect[\"max_y\"] - rect[\"min_y\"]\n",
    "        ax[1].add_patch(patches.Rectangle((rect[\"min_x\"], rect[\"min_y\"]), width=width, height=height, fill=False, linestyle=\"dashed\", linewidth=3, color=\"red\"))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def show_results(img_idx):\n",
    "    # Show results inline\n",
    "    plt.close()\n",
    "    image = images[img_idx]\n",
    "    image_aug_keypoints = valid_keypoints(aug_keypoints[img_idx], image)\n",
    "    image_aug_rects = keypoints_to_rects(image_aug_keypoints)\n",
    "    image_aug_keypoints = ia.KeypointsOnImage(np.array(image_aug_keypoints).flatten(), shape=image.shape)\n",
    "    return plot_img(images[img_idx], keypoints[img_idx], aug_images[img_idx], image_aug_keypoints, image_aug_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valid_keypoints(kpts, image):\n",
    "    # Returns any keypoints that are outside the width/height of the image\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    # Group by four (for each person)\n",
    "    runner_keypoints = keypoints_per_person(kpts)\n",
    "    # Copy over the \"valid\" keypoints (assume all are valid)\n",
    "    valid_keypoints = [e for e in runner_keypoints]\n",
    "    for kpts in runner_keypoints:\n",
    "        for k in kpts:\n",
    "            # If hidden, remove this runner\n",
    "            if k.x < 0 or k.x > width or k .y < 0 or k.y > height:\n",
    "                # Remove from valid if hidden\n",
    "                valid_keypoints = [k for k in valid_keypoints if k is not kpts]\n",
    "                break\n",
    "    # Whatever remains becomes the Bib click points for these runners\n",
    "    return valid_keypoints\n",
    "\n",
    "def keypoints_to_rects(kpts):\n",
    "    # Converts a set of keypoints to rectangles (min/max x/y)\n",
    "    rects = []\n",
    "    for kpt in kpts:\n",
    "        xs = [i.x for i in kpt]\n",
    "        ys = [i.y for i in kpt]\n",
    "        min_x, max_x = min(xs), max(xs)\n",
    "        min_y, max_y = min(ys), max(ys)\n",
    "        rects.append({\"min_x\": min_x, \"min_y\": min_y, \"max_x\": max_x, \"max_y\": max_y})\n",
    "    return rects\n",
    "\n",
    "def generate_csv_for_image_kpts(image, image_identifier, kpts):\n",
    "    # Writes a csv of all rectangles for this image\n",
    "    image_aug_keypoints = valid_keypoints(kpts, image)\n",
    "    image_aug_rects = keypoints_to_rects(image_aug_keypoints)\n",
    "    lines = []\n",
    "    for rect in image_aug_rects:\n",
    "        line = \"bib,%i,%i,%i,%i\" % (rect[\"min_x\"], rect[\"min_y\"], rect[\"max_x\"], rect[\"max_y\"])\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def save_image(image, image_identifier, kpts, augment_no = \"\", is_augmented = True):\n",
    "    unique_id = \"%s_%s%s\" % (image_identifier, \"aug\" if is_augmented else \"org\", augment_no)\n",
    "    print \"Saving %s image '%s' as '%s'...\" % (\"augmented\" if is_augmented else \"original\", image_identifier, unique_id)\n",
    "    imsave(\"%s/%s.jpg\" % (outdir, unique_id), image)\n",
    "    with open(\"%s/%s.csv\" % (outdir, unique_id), \"w\") as csv:\n",
    "        csv.write(generate_csv_for_image_kpts(image, image_identifier, kpts))\n",
    "\n",
    "# Process (copy) all original data\n",
    "org_data = dict(zip(image_identifiers, zip(images, keypoints)))\n",
    "for image_identifier, data in org_data.items():\n",
    "    img, kpts = data[0], data[1]\n",
    "    save_image(img, image_identifier, kpts, is_augmented = False)\n",
    "\n",
    "# Process (augment) all augmented data\n",
    "for i in range(augment_times):\n",
    "    # Process augment_times images\n",
    "    print \"Augmentation Round %i/%i...\" % (i + 1, augment_times)\n",
    "    seq_det = seq.to_deterministic()\n",
    "    aug_images = seq_det.augment_images(images)\n",
    "    aug_keypoints = seq_det.augment_keypoints(keypoints)\n",
    "    aug_data = dict(zip(image_identifiers, zip(aug_images, aug_keypoints)))\n",
    "    for image_identifier, data in aug_data.items():\n",
    "        img, kpts = data[0], data[1]\n",
    "        save_image(img, image_identifier, kpts, augment_no = i)\n",
    "    if not PROCESS_ALL_IMAGES:\n",
    "        # Save to test directory\n",
    "        show_results(0).savefig(\"%s/../../augmented_images_test/%s_aug.png\" % (outdir, i))\n",
    "        \n",
    "# Clean all temps when done!\n",
    "clean_temp_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
